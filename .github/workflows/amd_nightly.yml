name: AMD Nightly Kernel Tests

on:
  workflow_dispatch:
  push:
    branches: [main_perf]
  schedule:
    - cron: '0 0 * * *'  # runs nightly at midnight UTC

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  Nightly-CDNA-AMD:
    runs-on: ${{ matrix.runner }}
    strategy:
      matrix:
        runner: [linux-mi300-gpu-1]
      fail-fast: false # disables failing the entire job when one matrix entry fails
    timeout-minutes: 720 # self hosted runners can run jobs for longer than the default of 360 minutes
    container:
      image: rocm/pytorch:latest
      options: --device=/dev/kfd --device=/dev/dri --security-opt seccomp=unconfined --group-add video --user root
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      
      - name: Show Device Info
        run: |
          rocminfo | grep gfx
      
      - name: Uninstall Triton
        run: |
          pip uninstall -y triton
          rm -rf ~/.triton
          rm -rf ./triton/python/build

      - name: Install Triton
        run: |
          pip install triton==3.2.0
      
      - name: Show Triton version
        run: |
          pip show triton
      
      - name: Build
        run: |
          FLASH_ATTENTION_TRITON_AMD_ENABLE="TRUE" python setup.py install

      - name: Install dependencies for bench and misc
        run: |
          pip install numpy==1.24 matplotlib pandas tabulate

      - name: AMD Internal Tests
        run: |
          FLASH_ATTENTION_TRITON_AMD_ENABLE="TRUE" FLASH_ATTENTION_TRITON_AMD_AUTOTUNE=0 pytest flash_attn/flash_attn_triton_amd/test.py

      - name: Flash Attention Tests
        run: |
          FLASH_ATTENTION_TRITON_AMD_ENABLE="TRUE" FLASH_ATTENTION_TRITON_AMD_AUTOTUNE=0 pytest tests/test_flash_attn_triton_amd.py

      - name: AMD Bench
        run: |
          python flash_attn/flash_attn_triton_amd/bench.py -benchmark_fn flash_attn_func flash_attn_varlen_func flash_attn_with_kvcache

  Nightly-RDNA-AMD:
      runs-on: ${{ matrix.runner }}
      strategy:
        matrix:
          runner: [gfx1100]
        fail-fast: false # disables failing the entire job when one matrix entry fails
      timeout-minutes: 720 # self hosted runners can run jobs for longer than the default of 360 minutes
      container:
        image: rocm/pytorch:latest
        options: --device=/dev/kfd --device=/dev/dri --security-opt seccomp=unconfined --group-add video --user root
      steps:
        - name: Checkout
          uses: actions/checkout@v4
        
        - name: Show Device Info
          run: |
            rocminfo | grep gfx
        
        - name: Uninstall Triton
          run: |
            pip uninstall -y triton
            rm -rf ~/.triton
            rm -rf ./triton/python/build

        - name: Install Triton
          run: |
            pip install triton==3.2.0
        
        - name: Show Triton version
          run: |
            pip show triton
        
        - name: Build
          run: |
            FLASH_ATTENTION_TRITON_AMD_ENABLE="TRUE" python setup.py install

        - name: Flash Attention Tests
          run: |
            FLASH_ATTENTION_TRITON_AMD_ENABLE="TRUE" FLASH_ATTENTION_TRITON_AMD_AUTOTUNE=0 pytest tests/test_flash_attn_triton_amd.py::test_flash_attn_output
