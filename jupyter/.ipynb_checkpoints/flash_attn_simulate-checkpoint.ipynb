{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da99a79f-145c-44a9-9124-8d63141d49f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f5edb63-6c5c-41c6-b39c-d673d8ba1c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "327436ec-e618-4930-9659-ec80daffc5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 64])\n"
     ]
    }
   ],
   "source": [
    "# 使用常规方式计算的 Attention\n",
    "KT = torch.transpose(K, 0, 1)\n",
    "S = torch.matmul(Q, KT)\n",
    "P = torch.softmax(S, 1)\n",
    "O = torch.matmul(P, V)\n",
    "ouputBase = O\n",
    "print(ouputBase.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4492cbbe-01e4-445a-97a8-e4eebb9b4724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 64])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ouputBase.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b282cf34-e1cd-43e8-ad8f-387a21cbfb17",
   "metadata": {},
   "source": [
    "### 计算单个向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7fd24ec3-5c40-4cda-8183-719c50b87484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_m(x):\n",
    "    res_m = torch.max(x, 1, keepdim=True).values # keep dim 是为了后面\n",
    "    #print(\"res_m={}\".format(res_m.shape))\n",
    "    return res_m\n",
    "\n",
    "def func_f(x):\n",
    "    res_f = torch.exp(x - func_m(x))\n",
    "    #print(\"res_f={}\".format(res_f.shape))\n",
    "    return res_f # 包含在0维的broadcast操作\n",
    "\n",
    "def func_l(x):\n",
    "    res_l = torch.sum(func_f(x), 1, keepdim=True)\n",
    "    #print(\"res_l={}\".format(res_l.shape))\n",
    "    return res_l\n",
    "\n",
    "def func_softmax(x): \n",
    "    \"\"\"\n",
    "    等价于 F.softmax(x, 1)\n",
    "    \"\"\"\n",
    "    return func_f(x)/func_l(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e408fe-0cfc-43b0-ae22-d55bc614bf85",
   "metadata": {},
   "source": [
    "### 计算两个向量合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4a02c274-a082-4396-8356-3e4faf063d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_m2(x1, x2): \n",
    "    #print(func_m(x1))\n",
    "    #print(func_m(x2))\n",
    "    return torch.maximum(func_m(x1), func_m(x2))\n",
    "\n",
    "def func_f2(x1, x2):\n",
    "    #x = torch.cat(x1, x2, 1)\n",
    "    x1_part = torch.exp(func_m(x1) - func_m2(x1, x2)) * func_f(x1)\n",
    "    x2_part = torch.exp(func_m(x2) - func_m2(x1, x2)) * func_f(x2)\n",
    "    res = torch.cat((x1_part, x2_part), 1)\n",
    "    print(\"res_f2={}\".format(res.shape))\n",
    "    return res\n",
    "\n",
    "def func_l2(x1, x2):\n",
    "    x1_part = torch.exp(func_m(x1)-func_m2(x1, x2)) * func_l(x1)\n",
    "    x2_part = torch.exp(func_m(x2)-func_m2(x1, x2)) * func_l(x2)\n",
    "    res = (x1_part + x2_part)\n",
    "    print(\"res_l2={}\".format(res.shape))\n",
    "    return res\n",
    "\n",
    "def func_softmax2(x1, x2): \n",
    "    return func_f2(x1, x2) / func_l2(x1, x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b024f40-3509-4648-b312-ad23af28da02",
   "metadata": {},
   "source": [
    "### 分块计算 和 整体计算对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "fabf2f94-68b7-4042-8d03-f1b5ec10c61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_attention(Q, K, V, Br=1, Bc=1):\n",
    "    Qs = Q.split(Br, 0)\n",
    "    Ks = K.split(Bc, 0)\n",
    "    Vs = V.split(Bc, 0)\n",
    "    \n",
    "    Tr = len(Qs)\n",
    "    Tc = len(Vs)\n",
    "    \n",
    "    Output = torch.zeros(Q.shape)\n",
    "    Os = [o for o in Output.split(Br, 0)] # 因为split返回的tuple没法修改值 所以改为了list\n",
    "    ls = [torch.zeros(q.shape[0], 1) for q in Qs]\n",
    "    ms = [torch.ones(q.shape[0], 1) * float(\"-Inf\") for q in Qs] # -inf\n",
    "    for j in range(Tc):\n",
    "        # load Kj, Vj from HBM\n",
    "        Kj = Ks[j]\n",
    "        Vj = Vs[j]\n",
    "        for i in range(Tr):\n",
    "            # load li Oi Qi from HBM\n",
    "            li = ls[i]\n",
    "            mi = ms[i]\n",
    "            Oi = Os[i]\n",
    "            Qi = Qs[i]\n",
    "            \n",
    "            Kt = Kj.transpose(1, 0)\n",
    "            Sij = Qi.matmul(Kt)\n",
    "            mij, _ = Sij.max(1, keepdim=True)\n",
    "            minew = torch.maximum(mi, mij)\n",
    "            Pij = (Sij - mij).exp() # 为了计算稳定 避免溢出\n",
    "            lij = Pij.sum(1, keepdim=True) \n",
    "            linew = torch.exp(mi - minew) * li + torch.exp(mij - minew) * lij\n",
    "            old_part = Oi * li * torch.exp(mi - minew)\n",
    "            new_part = torch.exp(mij - minew) * Pij.matmul(Vj)\n",
    "            Oi = (old_part + new_part) / linew # 乘上原来的值 \n",
    "            \n",
    "            # write back Oi li to HBM\n",
    "            Os[i] = Oi\n",
    "            ls[i] = linew\n",
    "            ms[i] = minew\n",
    "    \n",
    "    Output = torch.cat(Os, 0)\n",
    "    return Output\n",
    "\n",
    "def attention(Q, K, V):\n",
    "    KT = torch.transpose(K, 1, 0)\n",
    "    S = torch.matmul(Q, KT)\n",
    "    P = torch.softmax(S, 1)\n",
    "    O = torch.matmul(P, V)\n",
    "    return O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "bfbc8c2a-cf7e-4579-bd23-eb3a14d97fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "N =8\n",
    "d = 3\n",
    "Br = 2\n",
    "Bc = 2\n",
    "Q = torch.randn((N, d))\n",
    "K = torch.randn((N, d))\n",
    "V = torch.randn((N, d))\n",
    "\n",
    "ori_res = attention(Q, K, V)\n",
    "split_res = split_attention(Q, K, V, Br=Br, Bc=Bc)\n",
    "CHECK_EQ(ori_res, split_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "96392d47-0379-42cd-b5d4-a3409b43db51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2309, -0.4989,  0.3301],\n",
       "        [ 0.4307, -0.4754,  0.7235],\n",
       "        [ 0.3869, -0.4787,  0.2893],\n",
       "        [ 0.4626, -0.4860,  1.0540],\n",
       "        [ 0.5465, -0.5487,  1.4449],\n",
       "        [ 0.6318, -0.5808,  1.0802],\n",
       "        [ 0.5865, -0.4663,  0.2924],\n",
       "        [ 0.3239, -0.4439,  0.2795]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "84ef546c-824d-44b1-9b71-241df2adbfec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2456,  0.5406,  0.8136],\n",
       "        [ 0.1798,  0.5123,  0.7575],\n",
       "        [ 0.1319,  0.4918,  0.7166],\n",
       "        [ 0.2535,  0.5440,  0.8204],\n",
       "        [ 0.2286,  0.5333,  0.7991],\n",
       "        [ 0.3873,  0.6014,  0.9345],\n",
       "        [-0.1630,  0.3653,  0.4650],\n",
       "        [-0.0550,  0.4116,  0.5572]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "546cf828-08ac-42ab-8bc1-3e88431423c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4864, -0.5113,  1.4111],\n",
       "        [ 0.8483, -0.6665, -0.3296],\n",
       "        [ 0.1248, -1.7141, -0.5245],\n",
       "        [ 0.1519, -1.7555, -0.5763],\n",
       "        [-1.7162, -1.1667,  1.9009],\n",
       "        [ 0.9712, -0.8719, -0.4632],\n",
       "        [-0.5934,  0.6552, -0.0957],\n",
       "        [-0.8440, -0.7500,  0.5437]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b54b491-d237-483b-afc8-4641baaca697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用常规方式计算的 Attention\n",
    "KT = torch.transpose(K, 0, 1)\n",
    "S = torch.matmul(Q, KT)\n",
    "P = torch.softmax(S, 1)\n",
    "O = torch.matmul(P, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e79c76c-7473-4c35-ad6f-cfa2cff6ccb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "O2 = attention(Q, K, V)\n",
    "CHECK_EQ(O, O2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "35b9940e-f3ee-42b3-98ee-a2320c987eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CHECK_EQ(O1, O2):\n",
    "    assert (O1 - O2).sum() > -1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5d294c77-7d37-49d4-9e03-f2da368e59b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5640,  1.8226, -0.0988],\n",
       "        [ 1.1099, -0.1472,  0.4329],\n",
       "        [-1.3287, -1.9497,  0.0321]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(3, 3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7d80d0e9-e795-4677-9442-0bc48b62c6c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5640,  1.1099, -1.3287],\n",
       "        [ 1.8226, -0.1472, -1.9497],\n",
       "        [-0.0988,  0.4329,  0.0321]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3c8cc8fa-eae7-4a72-99e7-bab8cafc1db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3]) torch.Size([3, 5])\n",
      "res_f2=torch.Size([3, 8])\n",
      "res_l2=torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "x = torch.randn(3, 8)\n",
    "x - func_m(x)\n",
    "# 直接计算\n",
    "res1 = F.softmax(x, 1)\n",
    "# 分布计算\n",
    "res2 = func_softmax(x)\n",
    "# 分段分布计算\n",
    "x1, x2 = x.split([3, 5], 1)\n",
    "print(x1.shape, x2.shape)\n",
    "res3 = func_softmax2(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "956cd5b2-4777-4f31-be98-26903d6300bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2059, 0.0911, 0.0528, 0.0326, 0.2141, 0.1049, 0.1402, 0.1584],\n",
       "        [0.0829, 0.0242, 0.0725, 0.0598, 0.0519, 0.2991, 0.0562, 0.3534],\n",
       "        [0.2934, 0.1037, 0.1191, 0.1432, 0.0084, 0.0292, 0.1676, 0.1354]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "37421540-ea5d-4669-997e-7d5a2dea4bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2059, 0.0911, 0.0528, 0.0326, 0.2141, 0.1049, 0.1402, 0.1584],\n",
       "        [0.0829, 0.0242, 0.0725, 0.0598, 0.0519, 0.2991, 0.0562, 0.3534],\n",
       "        [0.2934, 0.1037, 0.1191, 0.1432, 0.0084, 0.0292, 0.1676, 0.1354]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6ef21d8c-bca9-441b-87f5-53c8bf5a8f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 分块计算矩阵 attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e65bbe-da8e-420e-a4f9-d6e327c18c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qs = Q.split(Br, 0) # 按照Br切分Q\n",
    "Ks = Q.split(Bc, 0) # 按照Bc切分K\n",
    "Vs = Q.split(Bc, 0) # 按照Bc切分V\n",
    "\n",
    "def func_block_calc():\n",
    "    assert len(Vs) == len(Ks), \"K != v\"\n",
    "    for i in range(len(Qs)):\n",
    "        \n",
    "        for j in range(len(Vs)):\n",
    "            torch.matmul(q, Ks[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "89b6e74a-6368-4ca6-8a8b-1dd158edff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2 = x.split(4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d00f5512-f264-4320-b17c-e1b34136da84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7145],\n",
       "        [1.8365],\n",
       "        [1.9663]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_m2(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c4197f29-e534-4962-bf16-e26610aa3f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.7144],\n",
       "        [0.1132],\n",
       "        [1.1683]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(x, 1, keepdim=True).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "58c6dd3b-8f20-4213-b9ca-6d08ef8cf8d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0509, 0.2278, 0.0937, 0.2169, 0.0089, 0.1849, 0.0430, 0.1738],\n",
       "        [0.0126, 0.0479, 0.0301, 0.0149, 0.1444, 0.3562, 0.1616, 0.2324],\n",
       "        [0.3082, 0.1054, 0.0194, 0.2529, 0.0802, 0.1178, 0.0287, 0.0873]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e282d339-ef5b-4944-9021-35332a26576c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0509, 0.2278, 0.0937, 0.2169, 0.0089, 0.1849, 0.0430, 0.1738],\n",
       "        [0.0126, 0.0479, 0.0301, 0.0149, 0.1444, 0.3562, 0.1616, 0.2324],\n",
       "        [0.3082, 0.1054, 0.0194, 0.2529, 0.0802, 0.1178, 0.0287, 0.0873]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65de829b-211c-4916-9325-a48c9478d84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag1 = torch.diag(torch.Tensor([1, 2, 3]))\n",
    "n = torch.randn(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86104630-54a7-422d-a804-179170801658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6589, -0.3955, -0.7406],\n",
       "        [-1.1916,  0.6056, -0.2908],\n",
       "        [ 0.3575, -2.2452,  1.2301]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb4186c4-9db1-47ed-918a-8a31da9a51de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6589, -0.3955, -0.7406],\n",
       "        [-2.3832,  1.2111, -0.5817],\n",
       "        [ 1.0725, -6.7356,  3.6902]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(diag1, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d857fc5a-948a-45e5-8deb-a5458296832d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
